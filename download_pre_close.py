"""
ä¸‹è½½è‚¡ç¥¨æ˜¨æ”¶ä»·æ•°æ® - é«˜é€Ÿå¹¶å‘ç‰ˆæœ¬
ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è¯·æ±‚ï¼Œé€Ÿåº¦æå‡ 10-20 å€
"""

import pandas as pd
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import time
from tqdm import tqdm

def get_stock_pre_close_single(stock_code):
    """
    è·å–å•åªè‚¡ç¥¨çš„æ˜¨æ”¶ä»·
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
    
    Returns:
        dict: {'stock_code': code, 'pre_close': price} æˆ– None
    """
    # åˆ¤æ–­å¸‚åœºä»£ç 
    if stock_code.startswith('6'):
        secid = f"1.{stock_code}"  # ä¸Šæµ·
    elif stock_code.startswith('0') or stock_code.startswith('3'):
        secid = f"0.{stock_code}"  # æ·±åœ³
    elif stock_code.startswith('8') or stock_code.startswith('4'):
        secid = f"0.{stock_code}"  # åŒ—äº¤æ‰€
    else:
        secid = f"0.{stock_code}"  # é»˜è®¤æ·±åœ³
    
    base_url = "http://push2.eastmoney.com/api/qt/stock/get"
    params = {
        'secid': secid,
        'fields': 'f60',  # f60 æ˜¯æ˜¨æ”¶ä»·
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return None # çŠ¶æ€ç å¼‚å¸¸
            
        data = response.json()
        
        if data.get('data') and data['data'].get('f60'):
            pre_close = data['data']['f60']
            # è¿‡æ»¤æ‰æ— æ•ˆå€¼
            if pre_close == '-':
                return None
                
            return {
                'stock_code': stock_code,
                'pre_close': pre_close
            }
    except Exception as e:
        # ä»…åœ¨è°ƒè¯•æ—¶æ‰“å°
        # print(f"Error {stock_code}: {e}")
        pass
    
    return None


def _download_batch_internal(stock_codes, max_workers, desc):
    """å†…éƒ¨æ‰¹é‡ä¸‹è½½ helper"""
    results = []
    failed_codes = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_code = {
            executor.submit(get_stock_pre_close_single, code): code 
            for code in stock_codes
        }
        
        # ncols=80 é¿å…æ¢è¡Œæ··ä¹±
        with tqdm(total=len(stock_codes), desc=desc, ncols=80) as pbar:
            for future in as_completed(future_to_code):
                code = future_to_code[future]
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                    else:
                        failed_codes.append(code)
                except Exception:
                    failed_codes.append(code)
                pbar.update(1)
    
    return results, failed_codes

def download_pre_close_parallel(stock_codes, max_workers=50, max_retries=3):
    """
    å¹¶å‘ä¸‹è½½æ˜¨æ”¶ä»· (å¸¦é‡è¯•æœºåˆ¶)
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        max_retries: å¤±è´¥é‡è¯•æ¬¡æ•°
    
    Returns:
        DataFrame with columns: stock_code, pre_close
    """
    all_results = []
    
    print(f"å¼€å§‹å¹¶å‘ä¸‹è½½ {len(stock_codes)} åªè‚¡ç¥¨çš„æ˜¨æ”¶ä»·...")
    print(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")

    # 1. åˆæ¬¡ä¸‹è½½
    results, failed = _download_batch_internal(stock_codes, max_workers, "åˆæ¬¡ä¸‹è½½")
    all_results.extend(results)
    
    # 2. å¤±è´¥é‡è¯•
    for i in range(max_retries):
        if not failed:
            break
            
        print(f"\nğŸ”„ ç¬¬ {i+1}/{max_retries} æ¬¡å¤±è´¥é‡è¯• (å‰©ä½™ {len(failed)} åª)...")
        # é‡è¯•æ—¶é™ä½å¹¶å‘ï¼Œå‡å°‘è¢«å°æ¦‚ç‡
        retry_workers = max(5, int(max_workers * 0.5))
        time.sleep(1) # æ­‡ä¸€ä¼š
        
        results, new_failed = _download_batch_internal(failed, retry_workers, f"é‡è¯• {i+1}")
        all_results.extend(results)
        failed = new_failed
        
    print(f"\nâœ… æœ€ç»ˆæˆåŠŸ: {len(all_results)} åª")
    print(f"âŒ æœ€ç»ˆå¤±è´¥: {len(failed)} åª")
    
    if failed and len(failed) <= 10:
        print(f"å¤±è´¥è‚¡ç¥¨: {', '.join(failed)}")
    
    return pd.DataFrame(all_results)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸‹è½½è‚¡ç¥¨æ˜¨æ”¶ä»·æ•°æ®')
    parser.add_argument('--date', type=str, default='20251222', help='æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD')
    parser.add_argument('--workers', type=int, default=50, help='å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤50ï¼‰')
    args = parser.parse_args()
    
    date_str = args.date
    max_workers = args.workers
    
    # è¯»å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
    stocks_df = pd.read_csv('data/eastmoney_all_stocks.csv')
    stocks_df['stock_code'] = stocks_df['stock_code'].astype(str).str.zfill(6)
    
    # æ£€æŸ¥ tick æ•°æ®ç›®å½•
    tick_dir = Path(f'data/{date_str}/tick')
    if tick_dir.exists():
        tick_stocks = [f.stem for f in tick_dir.glob('*.parquet')]
        print(f"æ‰¾åˆ° {len(tick_stocks)} åªæœ‰ tick æ•°æ®çš„è‚¡ç¥¨")
        stock_codes = tick_stocks
    else:
        print(f"æœªæ‰¾åˆ° tick æ•°æ®ç›®å½•: {tick_dir}")
        print("è·å–æ‰€æœ‰è‚¡ç¥¨æ˜¨æ”¶ä»·")
        stock_codes = stocks_df['stock_code'].tolist()
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # å¹¶å‘ä¸‹è½½
    pre_close_df = download_pre_close_parallel(stock_codes, max_workers=max_workers)
    
    # è®¡ç®—è€—æ—¶
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed:.1f} ç§’")
    print(f"ğŸ“Š å¹³å‡é€Ÿåº¦: {len(stock_codes) / elapsed:.1f} åª/ç§’")
    
    # ä¿å­˜åˆ°å¯¹åº”æ—¥æœŸçš„ç›®å½•
    output_dir = Path(f'data/{date_str}')
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / f'stock_pre_close_{date_str}.csv'
    
    pre_close_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… å®Œæˆï¼å…±è·å– {len(pre_close_df)} åªè‚¡ç¥¨çš„æ˜¨æ”¶ä»·")
    print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºæ ·ä¾‹
    print("\næ ·ä¾‹æ•°æ®:")
    print(pre_close_df.head(10))


if __name__ == '__main__':
    main()
